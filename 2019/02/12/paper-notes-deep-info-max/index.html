<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="author" content="Zhenyue Qin"><link rel="alternative" href="/atom.xml" title="Deep Mental Artificial Intelligence" type="application/atom+xml"><link rel="icon" href="/images/general/Hua-Round.png"><title>Paper Notes on Learning Deep Representations by Mutual Information Estimation and Maximization - Deep Mental Artificial Intelligence</title><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/js/fancybox/jquery.fancybox.min.css"><!--[if lt IE 9]><script>(function(a,b){a="abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output progress section summary template time video".split(" ");for(b=a.length-1;b>=0;b--)document.createElement(a[b])})()</script><![endif]--><script src="/js/jquery-3.1.1.min.js"></script><script src="/js/fancybox/jquery.fancybox.min.js"></script></head><body style="opacity:0"><header class="head"><h1 class="head-title u-fl"><a href="/">Deep Mental Artificial Intelligence</a></h1><nav class="head-nav u-fr"><ul class="head-nav__list"><li class="head-nav__item"><a class="head-nav__link" href="/archives">目录</a></li></ul></nav></header><main class="main"><article class="post"><header class="post__head"><time class="post__time" datetime="2019-02-12T10:30:31.000Z">2019 - 02 - 12 21:30:31</time><h1 class="post__title"><a href="/2019/02/12/paper-notes-deep-info-max/">Paper Notes on Learning Deep Representations by Mutual Information Estimation and Maximization</a></h1><div class="post__main echo"><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>One core objective of deep learning is to discover useful representations. This paper explores the idea of maximizing the mutual information (MI) between the inputs and outputs of an encoder. Importantly, structure matters. It can substantially improve the representation’s quality by maximizing the average MI between local regions of inputting images and representations <sup><a href="#fn_T1" id="reffn_T1">T1</a></sup>, while gloabl MI computed from the entire input plays a stronger role in the reconstruction the full input given the representation. </p>
<p>The method in this paper is called Deep InfoMax (DIM) since it is closely related to the <em>information maximiazation principle</em> <sup><a href="#fn_Q1" id="reffn_Q1">Q1</a></sup>. This paper combines MI maximization with prior matching in a manner similar to <em>adversarial autoencoders</em> <sup><a href="#fn_Q2" id="reffn_Q2">Q2</a></sup>. The main contributions are the following: </p>
<ol>
<li>The formulation of Deep InfoMax (DIM), which simultaneously estimates and maximizes the MI between input data and high-level representaions <sup><a href="#fn_Q3" id="reffn_Q3">Q3</a></sup>. </li>
<li>Various priorities on global and local inputting information of MI, which can be turned for the suitability for classification and reconstruction-style tasks. </li>
<li>Usage of adversarial training to make the representation to have desired statistical characteristics <sup><a href="#fn_Q4" id="reffn_Q4">Q4</a></sup> specific to a prior.  </li>
<li>Introduction of two new metrics on evaluating representations, one based on Mutual Information Neural Estimation (MINE) and a neural dependency measure (NDM). </li>
</ol>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="MI-and-Generative-Models"><a href="#MI-and-Generative-Models" class="headerlink" title="MI and Generative Models"></a>MI and Generative Models</h3><p>The reconstruction error can be related to MI as follows <sup><a href="#fn_Q5" id="reffn_Q5">Q5</a></sup>, where $e$ and $d$ stands for encoding and decoding respectively: </p>
<script type="math/tex; mode=display">
I_e(X, Y) = H_e(X) - H_e(X|Y) \geq H_e(X) - R_{e, d}(X | Y)</script><p>where $X$ and $Y$ denote the inputs and outputs of the encoder which is applied to inputs sampled from some source distribution. $R_{e, d}$ denotes the expected reconstruction error given the codes of $Y$. </p>
<h3 id="Mutual-information-Estimation"><a href="#Mutual-information-Estimation" class="headerlink" title="Mutual-information Estimation"></a>Mutual-information Estimation</h3><p>In typical settings, models with reconstruction-typed objectives provide some guarantees on the amount of information encoded in their intermediate representations <sup><a href="#fn_Q6" id="reffn_Q6">Q6</a></sup>. Similar guarantees exist for bi-directional adversarial models, which adversarially train an encoder/decoder to match their respective joint distributions or to minimize the reconstruction error <sup><a href="#fn_Q7" id="reffn_Q7">Q7</a></sup>. </p>
<p>The infomax principle <sup><a href="#fn_F1" id="reffn_F1">F1</a></sup> advocates maximizing MI between the input and output. MINE learns an estimate of MI for continuous variables, which is strongly consistent and can be used to learn better implicitly bi-diretional generative models <sup><a href="#fn_Q8" id="reffn_Q8">Q8</a></sup>. </p>
<p>DIM follows the spirit of MINE in this regard, though DIM finds it is unnecessary to use a generator, and also unnecessary to use the exact KL-based formulation of MI. Instead, a simple alternative based on the Jenson-Shannon divergence is more stable and provides better results. </p>
<p>More significantly, DIM can leverage local structure in the input to improve the suitbality of representations for classifications <sup><a href="#fn_Q9" id="reffn_Q9">Q9</a></sup>. </p>
<p>It has been shown in the case of discrete MI that data augmentations and other transformations can be used to avoid degenerate solutions <sup><a href="#fn_Q10" id="reffn_Q10">Q10</a></sup>. </p>
<p>Proposed independently of DIM, Contrastive Predictive Coding is a MI-based approach that, like DIM, maximizes MI between gloabl and local representation pairs. CPC shares some motivations and computations with DIM, but there are important ways in which CPC and DIM differ. CPC processes local features sequentially to build partial “summary features”, which are used to make predictions about specific local features in the “future” of each summary feature. This equates to ordered autoregression over the local features, and requires training separate estimators for each temporal offset at which one would like to predict the future. In contrast, the basic version of DIM uses a single summary feature that is a function of all local features, and this “global” feature predicts all local features simultaneously in a single step using a single estimator. Note that, when using occlusions during training, DIM performs both “self” predictions and orderless autoregression. <sup><a href="#fn_Q11" id="reffn_Q11">Q11</a></sup></p>
<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><p>Marginal distribution of latent variable $y$ <sup><a href="#fn_Q13" id="reffn_Q13">Q13</a></sup></p>
<script type="math/tex; mode=display">
\begin{align}
U_{\psi, P}(y)     &= \sum_{x \in X} p(y | x) p(x) \\
                &= \sum_{i=1}^{N} p(y | x) (\frac{\delta(x)}{N})
\end{align}</script><script type="math/tex; mode=display">
L_{\hat{w}, \hat{\psi}} = \underset{\hat{w}, \hat{\psi}} {\arg \max} \frac{1}{M^{2}} \sum_{i=1}^{M^2} \hat{I} _ {\hat{w}, \hat{\psi}} (C_{\psi}^{i} (X) ; E_{\psi}(X))</script><p><sup><a href="#fn_Q12" id="reffn_Q12">Q12</a></sup></p>
<script type="math/tex; mode=display">
\hat{D} _ {\phi} (V || U) = \underset{\psi} {\arg\min} \text{ } \underset{\phi} {\arg\max} E_{V}[\log D_{\phi}(y)] + E_{P}[\log (1 - D_{\phi}{ (E_{\psi}(x)) })]</script><p>Note that the parameter $w$ is not involved in calculating the distance between $V$ and $U$. </p>
<p>Overall objective</p>
<script type="math/tex; mode=display">
\underset{w_1, w_2, \phi}{\arg\max} \big( 
\alpha I_{\hat{w_1}, \hat{\phi}} (X; E_{\phi} (X)) + 
\frac{\beta}{M^{2}} \sum_{i=1}^{M^2} \hat{I} _ {\hat{w_2}, \hat{\psi}} (C_{\psi}^{i} (X) ; E_{\psi}(X))
\big) 
+ \underset{\psi} {\arg\min} \text{ } \underset{\phi} {\arg\max} \hat{D} _ {\phi} (V || U)</script><h1 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h1><h2 id="Thoughts"><a href="#Thoughts" class="headerlink" title="Thoughts"></a>Thoughts</h2><p><sup><a href="#fn_T1" id="reffn_T1">T1</a></sup> Can we follow the same spirit of Mask R-CNN to propose RoIs? </p>
<h2 id="Future"><a href="#Future" class="headerlink" title="Future"></a>Future</h2><p><sup><a href="#fn_F1" id="reffn_F1">F1</a></sup> Read “infomax principle”. </p>
<h2 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h2><p><sup><a href="#fn_Q1" id="reffn_Q1">Q1</a></sup> What is “information maximization principle”?<br><sup><a href="#fn_Q2" id="reffn_Q2">Q2</a></sup> What is “adversarial autoencoders”?<br><sup><a href="#fn_Q3" id="reffn_Q3">Q3</a></sup> What are those “high-level representations”?<br><sup><a href="#fn_Q4" id="reffn_Q4">Q4</a></sup> What is a “desired statistics”?<br><sup><a href="#fn_Q5" id="reffn_Q5">Q5</a></sup> I don’t understand the equation.<br><sup><a href="#fn_Q6" id="reffn_Q6">Q6</a></sup> Why?<br><sup><a href="#fn_Q7" id="reffn_Q7">Q7</a></sup> I don’t understand this sentence at all.<br><sup><a href="#fn_Q8" id="reffn_Q8">Q8</a></sup> What are “implicitly bi-directional generative models”?<br><sup><a href="#fn_Q9" id="reffn_Q9">Q9</a></sup> Only classifications.<br><sup><a href="#fn_Q10" id="reffn_Q10">Q10</a></sup> What are “degenerated solutions”?<br><sup><a href="#fn_Q11" id="reffn_Q11">Q11</a></sup> I don’t quite understand the paragraph about CPC.<br><sup><a href="#fn_Q12" id="reffn_Q12">Q12</a></sup> Can we make $C_{\psi}^{i}$ as different as possible?<br><sup><a href="#fn_Q13" id="reffn_Q13">Q13</a></sup> How to solve this by SGD. </p>
</div></header><footer class="post__foot u-cf"><ul class="post__tag u-fl"><li class="post__tag__item"><a class="post__tag__link" href="/tags/Paper-Notes/">Paper Notes</a></li></ul></footer></article><section class="reward"><a class="btn-reward" href="#">打赏</a><div class="reward-wrapper clearfix"><img src="/img/wechat.png" title="支付宝"></div></section><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});
MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for(i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="//cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></main><footer class="foot"><div class="foot-copy">&copy; 2016 - 2019 Zhenyue Qin</div></footer><script src="/js/scroller.js"></script><script src="/js/main.js"></script></body></html>