<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="author" content="Zhenyue Qin"><link rel="alternative" href="/atom.xml" title="Deep Neuropathic Network" type="application/atom+xml"><link rel="icon" href="/images/general/Hua-Round.png"><title>Lecture Notes on Stanford CS231n Lecture 9 CNN Architectures - Deep Neuropathic Network</title><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/js/fancybox/jquery.fancybox.min.css"><!--[if lt IE 9]><script>(function(a,b){a="abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output progress section summary template time video".split(" ");for(b=a.length-1;b>=0;b--)document.createElement(a[b])})()</script><![endif]--><script src="/js/jquery-3.1.1.min.js"></script><script src="/js/fancybox/jquery.fancybox.min.js"></script></head><body style="opacity:0"><header class="head"><h1 class="head-title u-fl"><a href="/">Deep Neuropathic Network</a></h1><nav class="head-nav u-fr"><ul class="head-nav__list"><li class="head-nav__item"><a class="head-nav__link" href="/archives">Articles</a></li><li class="head-nav__item"><a class="head-nav__link" href="/research">Research</a></li><li class="head-nav__item"><a class="head-nav__link" href="/music">Music</a></li><li class="head-nav__item"><a class="head-nav__link" href="/about">About</a></li></ul></nav></header><main class="main"><article class="post"><header class="post__head"><time class="post__time" datetime="2019-02-10T03:36:03.000Z">2019 - 02 - 10 14:36:03</time><h1 class="post__title"><a href="/2019/02/10/lecture-notes-cs231-09/">Lecture Notes on Stanford CS231n Lecture 9 CNN Architectures</a></h1><div class="post__main echo"><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>In this lecture, Serena conducted case studies of various commonly-used CNN architectures, including AlexNet, VGG, GoogLeNet, and Resnet. </p>
<h1 id="Common-CNN-Architectures"><a href="#Common-CNN-Architectures" class="headerlink" title="Common CNN Architectures"></a>Common CNN Architectures</h1><h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p>AlexNet was the first convolutional networks employed in the ILSVRC Challenge and was the winner in 2012. It consists of various convolutional layers, with two fully-connected at the very end. Today, people, also not as frequent as back then, still use this model for extracting features from ImageNet. </p>
<h2 id="ZFNet"><a href="#ZFNet" class="headerlink" title="ZFNet"></a>ZFNet</h2><p>ZFNet was the winner of ILSVRC 2013. This model is just tuning the hyperparameters of AlexNet with nothing special. </p>
<h2 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h2><p>VGGNet came with the second place in ILSVRC 2014. Compared with AlexNet, VGGNet apply much smaller filters with a size of 3x3. </p>
<h3 id="Effects-of-Stacked-Receptive-Fields"><a href="#Effects-of-Stacked-Receptive-Fields" class="headerlink" title="Effects of Stacked Receptive Fields"></a>Effects of Stacked Receptive Fields</h3><p>We explain using a statement that </p>
<blockquote>
<p>Stack of three 3x3 conv (stride 1) layers has same effective receptive field as one 7x7 conv layer. </p>
</blockquote>
<p>We measure the effect of a stack of receptive fields as the coverage of a pixel in the final feature map over the initial input feature map. For example, a 3x3 input feature map will be converted into 1x1 after a 3x3 conv layer with stride 1. That is, a pixel of the 1x1 feature map can cover 3x3 features in the input. Therefore, we say this conv layer has an effect of a 3x3 layer. </p>
<p>However, things get tricker after introducing a stack of conv layers. Let’s first consider a stack of two 3x3 conv layers, both with stride 1. Now, a 5x5 layer will turn to 1x1 layer. Therefore, we say that a stack of two 3x3 layers has the same effective receptive field as one 5x5 layer. </p>
<p>Similarly, a stack of three 3x3 conv (stride 1) layers has same effective receptive field as one 7x7 conv layer. </p>
<h3 id="Why-use-smaller-filters"><a href="#Why-use-smaller-filters" class="headerlink" title="Why use smaller filters"></a>Why use smaller filters</h3><ol>
<li>We can then have deeper structures, by which we can have more non-linearities. </li>
<li>We can have fewer parameters. For example, a stack of three 3x3 conv layers have <script type="math/tex; mode=display">
3 \times (3^2 \cdot C_{in} \cdot C_{out})</script>parameters, where $C$ stands for channels and we assume channel numbers are retained, whereas there are <script type="math/tex; mode=display">
7^2 \cdot C_{in} \cdot C_{out}</script>parameters for a single 7x7 conv layer. </li>
</ol>
<h3 id="Some-Observations"><a href="#Some-Observations" class="headerlink" title="Some Observations"></a>Some Observations</h3><ol>
<li>Memories mainly are in the early layers. </li>
<li>Parameters mostly appear in the fully connected layers. </li>
</ol>
<h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><p>GOogLeNet was the winner of ILSVRC 2014. </p>
<h3 id="Inception-Module"><a href="#Inception-Module" class="headerlink" title="Inception Module"></a>Inception Module</h3><p>Unlike previous networks that did not demonstrate modularity, GoogLeNet designs good local network topologies and then stack these modules on top of each other. However, the parallel filters within each inception module can result in very heavy computational complexity. We introduce <code>bottleneck</code> layers to alleviate this problem. </p>
<h3 id="Other-Insights"><a href="#Other-Insights" class="headerlink" title="Other Insights"></a>Other Insights</h3><ol>
<li>No Fully-Connected layers. </li>
<li>Only 5 million parameters.</li>
<li>Auxilliary classification outputs to inject additional gradient at lower layers. </li>
</ol>
<h2 id="Residual-Network"><a href="#Residual-Network" class="headerlink" title="Residual Network"></a>Residual Network</h2><p>The Residual Network (ResNet) is the ILSVRC’15 winnner, and can go as deep as you like. </p>
<h3 id="Hypothesis"><a href="#Hypothesis" class="headerlink" title="Hypothesis"></a>Hypothesis</h3><p>The deeper model should perform at least as well as the shallower model. </p>
<h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p>Use network layers to fit a residual mapping instead of directly trying to fit a desired underlying mapping. In other words, we learn additional information in each layer. </p>
</div></header><footer class="post__foot u-cf"><ul class="post__tag u-fl"><li class="post__tag__item"><a class="post__tag__link" href="/tags/Lecture-Notes/">Lecture Notes</a></li></ul></footer></article></main><footer class="foot"><div class="foot-copy">&copy; 1994 - 2020 Zhenyue Qin</div></footer><script src="/js/scroller.js"></script><script src="/js/main.js"></script></body></html>