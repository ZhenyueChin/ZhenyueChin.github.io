<!DOCTYPE html>


  <html class="light page-post">


<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Learning Notes on Expectation-Maximization Algorithm | Deep Mental Artificial Intelligence</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="forsigner,前端,设计,Hexo主题,前端开发,用户体验,设计,frontend,design,nodejs,JavaScript">
  

  <meta name="description" content="This post explains the idea of Expectation-Maximization (EM) and why EM is intractable for tackling the problem of constructing an autoencoder.  The Expectation-Maximization Algorithm is an iterative">
<meta property="og:type" content="article">
<meta property="og:title" content="Learning Notes on Expectation-Maximization Algorithm">
<meta property="og:url" content="https://zhenyueqin.github.io/2019/04/01/learning-notes-em/index.html">
<meta property="og:site_name" content="Deep Mental Artificial Intelligence">
<meta property="og:description" content="This post explains the idea of Expectation-Maximization (EM) and why EM is intractable for tackling the problem of constructing an autoencoder.  The Expectation-Maximization Algorithm is an iterative">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://zhenyueqin.github.io/2019/04/01/learning-notes-em/em_autoencoder.jpg">
<meta property="og:updated_time" content="2019-04-06T05:32:25.182Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Learning Notes on Expectation-Maximization Algorithm">
<meta name="twitter:description" content="This post explains the idea of Expectation-Maximization (EM) and why EM is intractable for tackling the problem of constructing an autoencoder.  The Expectation-Maximization Algorithm is an iterative">
<meta name="twitter:image" content="https://zhenyueqin.github.io/2019/04/01/learning-notes-em/em_autoencoder.jpg">

  

  
    <link rel="icon" href="/images/general/Hua-Round.png">
  

  <link href="/css/styles.css?v=c114cbeddx" rel="stylesheet">


  
    <link rel="stylesheet" href="/css/personal-style.css">
  

  

  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?57e94d016e201fba3603a8a2b0263af0";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  
  <script type="text/javascript">
	(function(){
	    var bp = document.createElement('script');
	    var curProtocol = window.location.protocol.split(':')[0];
	    if (curProtocol === 'https') {
	        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
	    }
	    else {
	        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
	    }
	    var s = document.getElementsByTagName("script")[0];
	    s.parentNode.insertBefore(bp, s);
	})();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



  

</head>
</html>
<body>


  
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><span id="toolbox-mobile" class="toolbox-mobile">盒子</span>
  

  <div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">盒子</span>
      <i class="icon-angle-down"></i>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a class="CIRCLE" href="/archives/" rel="noopener noreferrer" target="_self">
            博客
          </a>
        </li>
      
        <li class="item-toolbox">
          <a class="CIRCLE" href="/category/" rel="noopener noreferrer" target="_self">
            分类
          </a>
        </li>
      
        <li class="item-toolbox">
          <a class="CIRCLE" href="/tag/" rel="noopener noreferrer" target="_self">
            标签
          </a>
        </li>
      
        <li class="item-toolbox">
          <a class="CIRCLE" href="/link/" rel="noopener noreferrer" target="_self">
            友链
          </a>
        </li>
      
        <li class="item-toolbox">
          <a class="CIRCLE" href="/about/" rel="noopener noreferrer" target="_self">
            关于
          </a>
        </li>
      
        <li class="item-toolbox">
          <a class="CIRCLE" href="/search/" rel="noopener noreferrer" target="_self">
            搜索
          </a>
        </li>
      
    </ul>
  </div>


</div>




<div class="content content-post CENTER">
   <article id="post-learning-notes-em" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">Learning Notes on Expectation-Maximization Algorithm</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2019.04.01</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>Zhenyue Qin</span>
        </span>
      

      
  <span class="article-category">
    <i class="icon-list"></i>
    <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>
  </span>



      

      
      
    </div>
  </header>

  <div class="article-content">
    
      <p>This post explains the idea of Expectation-Maximization (EM) and why EM is intractable for tackling the problem of constructing an autoencoder. </p>
<p>The Expectation-Maximization Algorithm is an iterative process, with $n$ randomly sampled latent variables $z$. </p>
<p>We first define </p>
<script type="math/tex; mode=display">L(\theta) = \log p_{\theta}(x)</script><p>as the $\log$ likelihood of a random variable $x$. and </p>
<script type="math/tex; mode=display">L(\theta_{n}) = \log p_{\theta_{n}}(x)</script><p>as the approximated $\log$ likelihood of the random variable $x$. </p>
<p>We wish to minimise the difference between these two likelihoods, which we express as</p>
<script type="math/tex; mode=display">
L(\theta) - L(\theta_{n}) = \log p_{\theta}(x) - \log p_{\theta_{n}}(x) = \Delta(\theta | \theta_{n})</script><p>We then wish to find the $\arg \max$ of $\theta$ so that $\Delta(\theta | \theta_{n})$ is maximised.</p>
<p>As a consequence of $\theta$ having been altered, we will also need to update $\theta_{n}$. </p>
<p>The concrete algorithm is as follows: </p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
\Sigma(\theta | \theta_{n}) &= \log p_{\theta}(x) - \log p_{\theta_{n}} (x) \\
&= \log p_{\theta} (x) - \log p_{\theta_{n}} (x) \\ 
&= \log \int p_{\theta} (x | z) p_{\theta} (z) dz - \log p_{\theta_{n}} (x) \\ 
&= \log \int p_{\theta} (x | z) p_{\theta}(z) \frac{q_{\theta_{n}}(z | x)}{q_{\theta_{n}}(z | x)} dz - \log p_{\theta_{n}}(x) \\ 
&= \log E_{z \sim q_{\theta_{n}}(z | x)} \frac{p_{\theta}(x | z) p_{\theta} (z)}{q_{\theta_{n}}(z | x)} - \log p_{\theta_{n}}(x) \\
&\geq E_{z \sim q_{\theta_{n}}(z | x)} \log \frac{p_{\theta}(x | z)p_{\theta}(z)}{q_{\theta_{n}}(z | x)} - \log p_{\theta_{n}}(x) \\ 
&= E_{z \sim q_{\theta_{n}} (z | x)} \log \frac{p_{\theta}(x | z) p_{\theta}(z)}{q_{\theta_{n}}(z | x) p_{\theta_{n}} (x)}
\end{aligned}
\end{equation}</script><p>In order to find the $\arg \max$ of $\theta$ so that $\Delta(\theta | \theta_{n})$ is maximised, we freeze </p>
<script type="math/tex; mode=display">
q_{\theta_{n}}(x)</script><p>and do</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
L(\theta) - L(\theta_{n}) &= \underset{\theta}{\arg \max} \big \{ \log p_{\theta_{n}} (x) + \Delta(\theta | \theta_{n}) \big \} \\ 
&= \underset{\theta}{\arg \max} \big \{ \log p_{\theta_{n}} (x) + E_{z \sim q_{\theta_{n}}(z | x)} \log \frac{p_{\theta} (x | z) p_{\theta} (z)}{q_{\theta_{n}}(z | x) p_{\theta_{n}}(x)} \big \} \\ 
&= \underset{\theta}{\arg \max} \big \{ E_{z \sim q_{\theta_{n}}(z | x)} \log p_{\theta} (x | z) p_{\theta}(z) \big \}
\end{aligned}
\end{equation}</script><p>The above equation is a form of an autoencoder, as the Figure below shows. The latent vectors $z$ are fixed, and we do SGD for the decoder. Afterwards, we update encoder and make the parameters of the decoder fixed. </p>
<center>
<img src="/2019/04/01/learning-notes-em/em_autoencoder.jpg" width="400" hspace="10">
</center>

<p>If we solve the generative model in this way, we need to do the SGD for $\ln p(x, z | \theta)$, followed by do the SGD for $p(z | x, \theta)$. This will be very time consuming (intractable). This is because unlike VAE, where we have a prior on the distribution $p(z)$, EC has to generate a large number of $z$ and then send them to the decoder to get $\hat{x}$. </p>
<p>Moreover, this will not guarantee the smoothness of the learned $z$ space. </p>

    
  </div>

</article>


   

   



</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">Close</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a class="CIRCLE" href="/archives/" rel="noopener noreferrer" target="_self">
              博客
            </a>
          </li>
        
          <li class="item-toolbox">
            <a class="CIRCLE" href="/category/" rel="noopener noreferrer" target="_self">
              分类
            </a>
          </li>
        
          <li class="item-toolbox">
            <a class="CIRCLE" href="/tag/" rel="noopener noreferrer" target="_self">
              标签
            </a>
          </li>
        
          <li class="item-toolbox">
            <a class="CIRCLE" href="/link/" rel="noopener noreferrer" target="_self">
              友链
            </a>
          </li>
        
          <li class="item-toolbox">
            <a class="CIRCLE" href="/about/" rel="noopener noreferrer" target="_self">
              关于
            </a>
          </li>
        
          <li class="item-toolbox">
            <a class="CIRCLE" href="/search/" rel="noopener noreferrer" target="_self">
              搜索
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-post">
    

    

    
    

    

    
    

    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
    <div id="comment" class="vcomment"></div>
    <script>
        var notify = 'true' == true ? true : false;
        var verify = 'true' == true ? true : false;
        var GUEST_INFO = ['nick','mail','link'];
        var guest_info = 'nick,mail,link'.split(',').filter(function(item){
            return GUEST_INFO.indexOf(item) > -1
        });
        guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
        window.valine = new Valine({
            el: '.vcomment',
            notify: notify,
            verify: verify,
            appId: "",
            appKey: "",
            avatar:'mm',
            placeholder: "Just go go",
            guest_info:guest_info,
            pageSize:'10'
        });
    </script>
  
    

  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
